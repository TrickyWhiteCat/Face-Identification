{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHJ-OTLnbkTS"
      },
      "source": [
        "Reference FaceAlignment Model\n",
        "- https://paperswithcode.com/task/face-alignment\n",
        "- https://github.com/zhenglinzhou/star (STAR Loss: Reducing Semantic Ambiguity in Facial Landmark Detection)\n",
        "- https://github.com/huangyangyu/ADNet\n",
        "\n",
        "\n",
        "| Dataset      | Best Model           | Paper | Code  | Compare |\n",
        "|--------------|----------------------|-------|-------|---------|\n",
        "| 300W         | STAR                 | üìÑ    | üîó   |         |\n",
        "| WFLW         | LDEQ                 | üìÑ    | üîó   |         |\n",
        "| COFW         | SH-FAN               | üìÑ    | üîó   |         |\n",
        "| AFLW-19      | FaRL-B (epoch 16)    | üìÑ    | üîó   |         |\n",
        "| AFLW2000-3D  | MNN+OR (reannotated) | üìÑ    | üîó   |         |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRcM2pC1QeDw"
      },
      "source": [
        "# ***0. CONNECT GOOGLE DRIVE***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StHQeJEXQdpo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UftoQ33ylHPN"
      },
      "source": [
        "# ***1. WFLW DATASET AND STRUCTURE DATA FOR TRAINING***\n",
        "https://wywu.github.io/projects/LAB/WFLW.html\n",
        "\n",
        "https://datasets.activeloop.ai/docs/ml/datasets/wflw-dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd1VN-0dklT1"
      },
      "source": [
        "\n",
        "```\n",
        "# the dataset directory:\n",
        "|-- ${image_dir}\n",
        "   |-- WFLW\n",
        "      | -- WFLW_images\n",
        "\n",
        "|-- ${annot_dir}\n",
        "   |-- WFLW\n",
        "      |-- train.tsv, test.tsv\n",
        "```\n",
        "\n",
        "https://github.com/ZhenglinZhou/STAR/blob/master/conf/alignment.py\n",
        "\n",
        "Quan s√°t c√°ch data_definition trong file alignment.py\n",
        "```python\n",
        "# /conf/alignment.py\n",
        "        # COFW\n",
        "        if self.data_definition == \"COFW\":\n",
        "            self.edge_info = (\n",
        "                (True, (0, 4, 2, 5)), # RightEyebrow\n",
        "                (True, (1, 6, 3, 7)), # LeftEyebrow\n",
        "                ...\n",
        "            )\n",
        "            self.nme_left_index = 16 # pupils\n",
        "            self.nme_right_index = 17 # pupils\n",
        "            ...\n",
        "        # 300W\n",
        "        elif self.data_definition == \"300W\":\n",
        "            self.edge_info = ...\n",
        "                \n",
        "        # WFLW\n",
        "        elif self.data_definition == \"WFLW\":     \n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read the provided metadata file to understand its structure\n",
        "metadata_path = '/content/train.tsv'\n",
        "\n",
        "# Since we're dealing with a TSV file, we'll use pandas to read it\n",
        "import pandas as pd\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "metadata_df = pd.read_csv(metadata_path, delimiter='\\t')\n",
        "\n",
        "# Display the first few rows of the dataframe to understand its structure\n",
        "metadata_df.head()\n"
      ],
      "metadata": {
        "id": "ejQ8y1Jo6XFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplake\n",
        "import deeplake\n",
        "ds = deeplake.load(\"hub://activeloop/wflw-train\")"
      ],
      "metadata": {
        "id": "CoQbpuU7_En0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deeplake\n",
        "ds_train = deeplake.load(\"hub://activeloop/wflw-train\")[:10]\n",
        "print(ds_train)\n",
        "img_list_train = ds_train['images'],\n",
        "anno_list_train = ds_train['boxes']\n",
        "print(img_list_train)\n",
        "print(anno_list_train)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Xem qua m·ªôt s·ªë h√¨nh ·∫£nh t·ª´ t·∫≠p hu·∫•n luy·ªán\n",
        "i=0\n",
        "image = ds_train['images'][i]  # Tensor(key='images', index=Index([0]))\n",
        "print(image)\n",
        "# In h√¨nh d·∫°ng v√† ki·ªÉu d·ªØ li·ªáu c·ªßa ·∫£nh\n",
        "print(\"Shape of the image:\", image.shape) # Shape of the image: (295, 285, 3)\n",
        "print(\"Data type of the image:\", image.dtype) # Data type of the image: uint8\n",
        "\n",
        "image = ds_train['images'][i].numpy()  # Chuy·ªÉn tensor sang NumPy array\n",
        "print(image) # Numpy array\n",
        "print(\"Shape of the image:\", image.shape) # Shape of the image: (295, 285, 3)\n",
        "print(\"Data type of the image:\", image.dtype) # Data type of the image: uint8\n",
        "\n",
        "# Hi·ªÉn th·ªã ·∫£nh\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Image {i}\")\n",
        "plt.show()\n",
        "\n",
        "# In th√¥ng tin c·∫•u tr√∫c c·ªßa bounding box\n",
        "box = ds_train['boxes'][i].numpy()  # L·∫•y th√¥ng tin bounding box v√† chuy·ªÉn sang NumPy array\n",
        "print(f\"Box shape for image {i}:\", box.shape)\n",
        "print(f\"First bounding box for image {i} (if multiple):\", box[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "LeP7RrPY_Ujt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ƒê·ªÉ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ t·∫≠p d·ªØ li·ªáu WFLW (ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n DeepLake) sang ƒë·ªãnh d·∫°ng TSV (.tsv) gi·ªëng nh∆∞ m·∫´u b·∫°n ƒë√£ cung c·∫•p, b·∫°n c·∫ßn th·ª±c hi·ªán m·ªôt s·ªë b∆∞·ªõc x·ª≠ l√Ω d·ªØ li·ªáu. D∆∞·ªõi ƒë√¢y l√† quy tr√¨nh c∆° b·∫£n:\n",
        "\n",
        "### B∆∞·ªõc 1: Truy C·∫≠p v√† L·∫•y D·ªØ Li·ªáu\n",
        "- ƒê·∫ßu ti√™n, truy c·∫≠p t·∫≠p d·ªØ li·ªáu WFLW t·ª´ DeepLake.\n",
        "- L·∫•y d·ªØ li·ªáu cho c√°c tensors c·∫ßn thi·∫øt nh∆∞ `images`, `boxes`, `keypoints`, v√† c√°c thu·ªôc t√≠nh kh√°c (`blurs`, `expressions`, `illuminations`, `makeups`, `occlusions`, `poses`).\n",
        "\n",
        "### B∆∞·ªõc 2: X·ª≠ L√Ω D·ªØ Li·ªáu\n",
        "- **X·ª≠ l√Ω ·∫¢nh v√† ƒê∆∞·ªùng d·∫´n:** ƒê·ªëi v·ªõi m·ªói ·∫£nh, b·∫°n c·∫ßn l∆∞u ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ·ª©ng ho·∫∑c t·∫°o m·ªôt ƒë∆∞·ªùng d·∫´n gi·∫£ l·∫≠p n·∫øu ƒëang l√†m vi·ªác v·ªõi d·ªØ li·ªáu ·∫£nh tr·ª±c ti·∫øp.\n",
        "- **X·ª≠ l√Ω ƒêi·ªÉm m·ªëc (Keypoints):** Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu keypoints (ƒëi·ªÉm m·ªëc) th√†nh chu·ªói t·ªça ƒë·ªô. M·ªói ƒëi·ªÉm m·ªëc s·∫Ω c√≥ hai gi√° tr·ªã t·ªça ƒë·ªô x, y.\n",
        "- **X·ª≠ l√Ω H·ªôp Gi·ªõi h·∫°n (Bounding Box):** Tr√≠ch xu·∫•t t·ªça ƒë·ªô c·ªßa h·ªôp gi·ªõi h·∫°n (n·∫øu c√≥) cho m·ªói ·∫£nh. Trong tr∆∞·ªùng h·ª£p c·ªßa b·∫°n, c√≥ v·∫ª nh∆∞ ch·ªâ c√≥ ba gi√° tr·ªã, v√¨ v·∫≠y c·∫ßn x√°c ƒë·ªãnh c√°ch ch√∫ng ƒë∆∞·ª£c bi·ªÉu di·ªÖn v√† x·ª≠ l√Ω ch√∫ng cho ph√π h·ª£p.\n",
        "- **X·ª≠ l√Ω Thu·ªôc T√≠nh:** Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã thu·ªôc t√≠nh nh∆∞ `occlusion`, `pose`, `make-up`, `illumination`, `blur`, v√† `expression` th√†nh ƒë·ªãnh d·∫°ng s·ªë (th∆∞·ªùng l√† 0 ho·∫∑c 1).\n",
        "\n",
        "### B∆∞·ªõc 3: Ghi ra File TSV\n",
        "- K·∫øt h·ª£p t·∫•t c·∫£ c√°c th√¥ng tin ƒë√£ x·ª≠ l√Ω th√†nh m·ªôt d√≤ng cho m·ªói h√¨nh ·∫£nh. M·ªói d√≤ng s·∫Ω bao g·ªìm ƒë∆∞·ªùng d·∫´n ·∫£nh, chu·ªói t·ªça ƒë·ªô ƒëi·ªÉm m·ªëc, t·ªça ƒë·ªô h·ªôp gi·ªõi h·∫°n, v√† gi√° tr·ªã c·ªßa c√°c thu·ªôc t√≠nh.\n",
        "- Ghi t·∫•t c·∫£ c√°c d√≤ng v√†o m·ªôt file TSV.\n",
        "\n"
      ],
      "metadata": {
        "id": "41AbjONKEx6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1' Load Dataset form Kaggle***\n",
        "- Sau khi processing, t√¥i push dataset zip file to Kaggle\n",
        "https://www.kaggle.com/datasets/cngonngc/facealign-wflwds-adnetstarloss-proccolab-upkaggle"
      ],
      "metadata": {
        "id": "I8Qp3hAR5mv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1''. Load EVALUATION Dataset - EDA - Processing Yolov5***\n",
        "- FOR EVALUATION: CELEBAdataset"
      ],
      "metadata": {
        "id": "bElwRb3O5dyE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qy2TDWOL5v4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kSCIFVNLtb2"
      },
      "source": [
        "# ***2. Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXMiC4bcdgot"
      },
      "source": [
        "\n",
        "Quan s√°t argparse trong main.py:\n",
        "https://github.com/ZhenglinZhou/STAR/blob/master/main.py\n",
        "\n",
        "```main.py python\n",
        "# main.py\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Entry Fuction\")\n",
        "    parser.add_argument(\"--mode\", type=str, default=\"train\", choices=[\"train\", \"test\"], help=\"train or test\")\n",
        "    parser.add_argument(\"--config_name\", type=str, default=\"alignment\", choices=[\"alignment\"], help=\"set configure file name\")\n",
        "    parser.add_argument(\"--pretrained_weight\", type=str, default=None, help=\"set pretrained model file name, if ignored then train the network without pretrain model\")\n",
        "    parser.add_argument(\"--work_dir\", type=str, default=\"./\", help=\"the directory of workspace\")\n",
        "    #parser.add_argument(\"--device_ids\", type=str, default=\"-1\", help=\"set device ids, -1 means use cpu device, >= 0 means use gpu device\")\n",
        "    #parser.add_argument('--device_ids', type=str, default=\"0\", help=\"set device ids, -1 means use cpu device, >= 0 means use gpu device\")\n",
        "    parser.add_argument('--device_ids', type=str, default=\"0,1,2,3\", help=\"set device ids, -1 means use cpu device, >= 0 means use gpu device\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQl3PueTemhW"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/colab\n",
        "!git clone https://github.com/zhenglinzhou/star\n",
        "# ModuleNotFoundError: No module named 'tensorboardX'\n",
        "# B·ªã l·ªói khi pip n√™n ko pip n·ªØa  !pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uH4OhRAsc3y"
      },
      "source": [
        "## ***2.1 Wandb, Note Bug in training processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EkPlSurlkZl"
      },
      "source": [
        "## ***2.2 PreTraining and Debug***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dQbQy03zTR"
      },
      "source": [
        "## 2.3 S·ª¨A ƒê·ªîI M√É NGU·ªíN and Use for Training\n",
        "S·ª≠a m√£ fork t·ª´ STAR, -> setup ·ªü git c√° nh√¢n, load l·∫°i x√†i cho nhanh.\n",
        "- Fix Bug requirements.txt\n",
        "- Fix Bug`evalues, evectors = torch.linalg.eigh(covars, UPLO='L') # Doan Ngoc Cuong fix`\n",
        "trong c√°c file `# !grep -rnw './' -e 'symeig'  # fix bug `\n",
        "\n",
        "Setup Wandb:\n",
        "- Setup wandb.init() and wandb.finish() trong main.py\n",
        "- Log training metrics trong lib/utility.py\n",
        "- Log valid metrics v√† save best model trong trainer.py\n",
        "- Th√™m INFO l∆∞u tr·ªØ save model trong lib/utility.py\n",
        "- Add args.pretrained_weights v√†o main.py, s·ª≠a c√°ch save_model with `net` thay v√¨ `best_net` ·ªü file `trainer.py`(best model save torch ƒë∆∞·ª£c log artifacts v√† lastest model ƒë∆∞·ª£c save torch ko log artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnSUMiJjDUGI"
      },
      "source": [
        "## 2.4 INFER - PREDECTION - SMALL REAL TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqmGP3ge-kbz"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/colab\n",
        "!git clone https://github.com/DoanNgocCuongBKEGNH/FaceAlignment_WFLWds_ADNetwithSTARloss.git --branch WFLWds_ADNetwithSTARLoss\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwghbtTDAFXc",
        "outputId": "733a56e4-9ff8-4374-9d20-62b4c768c779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'star'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 72 (delta 8), reused 69 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (72/72), 990.84 KiB | 7.86 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/zhenglinzhou/star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsXq8QLTXrkd"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "import wandb\n",
        "wandb.login(key=\"c8767797aae76cbcd389ff29929ace1ac3021161\")\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('doanngoccuong_nh/FaceAlignment_ADNetwithSTARloss/ADNetSTARLoss_bestmodel:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "# https://drive.usercontent.google.com/download?id=1aOx0wYEZUfBndYy_8IYszLPG_D2fhxrT&export=download&authuser=0\n",
        "# https://drive.usercontent.google.com/download?id=1aOx0wYEZUfBndYy_8IYszLPG_D2fhxrT\n",
        "# %cd /content/drive/MyDrive/colab\n",
        "%cd /content\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/u/0/uc?id=1aOx0wYEZUfBndYy_8IYszLPG_D2fhxrT', 'WFLW_STARLoss_NME_4_02_FR_2_32_AUC_0_605.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9F7Y_poA9DL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plL8PmQkYpnB"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/colab\n",
        "!git clone https://github.com/italojs/facial-landmarks-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3qEMzn0Zlvz"
      },
      "source": [
        "- Th√™m ƒë∆∞·ªùng d·∫´n landmark v√†o file demo.py\n",
        "- Th√™m ƒë∆∞·ªùng d·∫´n best model v√†o file demo.py\n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFie8Zr-9g2Z"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7L9S1O7KKuk"
      },
      "outputs": [],
      "source": [
        "%cd /content/FaceAlignment_WFLWds_ADNetwithSTARloss\n",
        "!python demo.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U_Rz6A2HzFW"
      },
      "source": [
        "- output ra 1 ƒë·ªëng DEBUG v√† Figure(640x480) ch·ªâ th·∫•y nh∆∞ n√†y, ko th·∫•y ·∫£nh ra g√¨ c·∫£, d√π trong code c√≥ plt.show().\n",
        "Nguy√™n nh√¢n c√≥ th·ªÉ l√† do ·∫£nh k√≠ch th∆∞·ªõc to qu√°.\n",
        "\n",
        "- Test ko n√™n ch·ªçn ·∫£nh b·ªã che 1 ph·∫ßn m·∫∑t\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ4RUlSVDYbz"
      },
      "source": [
        "## 2.5 INFER - EVALUATION on BIG TESTSET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUM_v-_vQpYg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejminQSiEGCa"
      },
      "source": [
        "# 3."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gH72d5jquJoy",
        "WA3zb3povXxg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}